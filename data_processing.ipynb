{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import features\n",
    "\n",
    "\n",
    "import skimage.feature\n",
    "from skimage.feature import graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glcm\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "coords = [[0, 0], [0, 1], [1, 1], [1, 0], [1, -1], [0, -1], [-1, -1], [-1, 0], [-1, 1]]\n",
    "\n",
    "def comb_idx(a, b, nb_chans):\n",
    "    return int(a*(nb_chans-1) - (a-1)*a/2 + (b-a -1))\n",
    "\n",
    "def glcm(patch, ranges, dirs, nb_bins, normalized=False, symmetric=False, sum=False):\n",
    "\n",
    "    nb_rows = patch.shape[0]\n",
    "    nb_cols = patch.shape[1]\n",
    "    try:\n",
    "        nb_chans = patch.shape[2]\n",
    "    except:\n",
    "        nb_chans = 1\n",
    "\n",
    "    if(sum):\n",
    "        glcm = np.zeros((len(ranges), nb_chans, nb_bins, nb_bins)).astype(np.int32)\n",
    "\n",
    "        for dist, dir, px, py, chan_src in itertools.product(range(len(ranges)),\n",
    "                                                             range(len(dirs)),\n",
    "                                                             range(nb_rows),\n",
    "                                                             range(nb_cols),\n",
    "                                                             range(nb_chans)):\n",
    "            direction = coords[dirs[dir]] * ranges[dist]\n",
    "\n",
    "            if nb_rows > px + direction[0] >= 0 and nb_cols > py + direction[1] >= 0:\n",
    "                try:\n",
    "                    src = patch[px, py, chan_src]\n",
    "                    dst = patch[px + direction[0], py + direction[1], chan_src]\n",
    "                except:\n",
    "                    src = patch[px, py]\n",
    "                    dst = patch[px + direction[0], py + direction[1]]\n",
    "\n",
    "                if (symmetric):\n",
    "                    glcm[dist, chan_src, dst, src] += 1\n",
    "                glcm[dist, chan_src, src, dst] += 1\n",
    "\n",
    "        if (normalized):\n",
    "            for dist, chan_src in itertools.product(range(len(ranges)),\n",
    "                                                         range(nb_chans)):\n",
    "                glcm = glcm.astype(np.float64)\n",
    "                min_glcm = np.min(glcm[dist, dir, chan_src, :, :])\n",
    "                max_glcm = np.max(glcm[dist, dir, chan_src, :, :])\n",
    "                glcm[dist, dir, chan_src, :, :] = (glcm[dist, dir, chan_src, :, :] - min_glcm) / (max_glcm - min_glcm)\n",
    "\n",
    "                # glcm[dist, chan_src, :, :] /= np.sum(glcm[dist, chan_src, :, :])\n",
    "\n",
    "        return glcm\n",
    "\n",
    "\n",
    "    else:\n",
    "        glcm = np.zeros((len(ranges), len(dirs), nb_chans, nb_bins, nb_bins)).astype(np.int32)\n",
    "\n",
    "        for dist, dir, px, py, chan_src in itertools.product(range(len(ranges)),\n",
    "                                                   range(len(dirs)),\n",
    "                                                   range(nb_rows),\n",
    "                                                   range(nb_cols),\n",
    "                                                   range(nb_chans)):\n",
    "            direction = coords[dirs[dir]] * ranges[dist]\n",
    "\n",
    "            if nb_rows > px + direction[0] >= 0 and nb_cols > py + direction[1] >= 0:\n",
    "                try:\n",
    "                    src = patch[px, py, chan_src]\n",
    "                    dst = patch[px + direction[0], py + direction[1], chan_src]\n",
    "                except:\n",
    "                    src = patch[px, py]\n",
    "                    dst = patch[px + direction[0], py + direction[1]]\n",
    "\n",
    "                    if(symmetric):\n",
    "                        glcm[dist, dir, chan_src, dst, src] += 1\n",
    "                    glcm[dist, dir, chan_src, src, dst] += 1\n",
    "\n",
    "        if(normalized):\n",
    "            for dist, dir, chan_src in itertools.product(range(len(ranges)),\n",
    "                                                                   range(len(dirs)),\n",
    "                                                                   range(nb_chans)):\n",
    "                glcm = glcm.astype(np.float64)\n",
    "                min_glcm = np.min(glcm[dist, dir, chan_src, :, :])\n",
    "                max_glcm = np.max(glcm[dist, dir, chan_src, :, :])\n",
    "                glcm[dist, dir, chan_src, :, :] = (glcm[dist, dir, chan_src, :, :] - min_glcm) / (max_glcm - min_glcm)\n",
    "                # glcm[dist, dir, chan_src, :, :] /= np.sum(glcm[dist, dir, chan_src, :, :])\n",
    "\n",
    "        return glcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories\n",
    "# Store your directories in a \"data\" folder in your working directory\n",
    "CURRENT_DIR = os.getcwd()\n",
    "TRAIN_DIR = CURRENT_DIR + \"\\\\data\\\\train\"\n",
    "TEST_DIR = CURRENT_DIR + \"\\\\data\\\\test\"\n",
    "\n",
    "# Create empty DataFrames for the train and test data\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "#input is a plt.imread object\n",
    "#output is a cropped plt.imread object\n",
    "def crop_image(image_path):\n",
    "    image = plt.imread(image_path)\n",
    "    temp = cv2.dilate(cv2.erode(image, np.ones((3,3), np.uint8), iterations=1), np.ones((3,3), np.uint8), iterations=1)\n",
    "    a = np.sum(temp, axis=0).nonzero()[0]\n",
    "    b = np.sum(temp, axis=1).nonzero()[0]\n",
    "    return image[b[0]:b[-1], a[0]:a[-1]]\n",
    "\n",
    "#input is a plt.imread object\n",
    "#output is a normalized plt.imread object\n",
    "def normalize_image(image):\n",
    "    return (image - np.min(image))/(np.max(image) - np.min(image))\n",
    "\n",
    "# Define a function to read and resize an image\n",
    "def read_and_resize_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    resized_image = cv2.resize(image, (128, 128))\n",
    "    # Convert the resized image to grayscale (2D array)\n",
    "    gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray_image  # Now, the image is a 2D NumPy array (grayscale)\n",
    "\n",
    "def process_image(DIR):\n",
    "\n",
    "    #Initiate Dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create an empty list to store the new rows\n",
    "    new_rows = []\n",
    "\n",
    "    # Iterate over the training directory and read in the images\n",
    "    for subdir in os.listdir(DIR):\n",
    "        subdir_path = os.path.join(DIR, subdir)\n",
    "        for image in os.listdir(subdir_path):\n",
    "            image_path = os.path.join(subdir_path, image)\n",
    "\n",
    "            # Read and resize the image\n",
    "            # resized_image = read_and_resize_image(image_path)\n",
    "            resized_image = crop_image(image_path)\n",
    "\n",
    "            # Create a new row for the train DataFrame\n",
    "            new_row = {\n",
    "                \"image\": resized_image,\n",
    "                \"label\": {\n",
    "                    \"NonDemented\": 0,\n",
    "                    \"VeryMildDemented\": 1,\n",
    "                    \"MildDemented\": 2,\n",
    "                    \"ModerateDemented\": 3\n",
    "                }[subdir]\n",
    "            }\n",
    "\n",
    "            # Add the new row to the list\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    # Concatenate the new rows to the train DataFrame\n",
    "    df = pd.DataFrame(new_rows)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process train and test DataFrames\n",
    "train_df = process_image(TRAIN_DIR)\n",
    "test_df = process_image(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean(img):\n",
    "    return np.mean(img)\n",
    "\n",
    "train_mean_df = pd.DataFrame()\n",
    "test_mean_df = pd.DataFrame()\n",
    "\n",
    "train_mean_df['mean'] = train_df['image'].apply(compute_mean)\n",
    "test_mean_df['mean'] = test_df['image'].apply(compute_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import shannon_entropy\n",
    "# Compute Entropy\n",
    "# input image\n",
    "# output entropy: value (float)\n",
    "def compute_entropy(img):\n",
    "    return shannon_entropy(img)\n",
    "\n",
    "train_entropy_df = pd.DataFrame()\n",
    "test_entropy_df = pd.DataFrame()\n",
    "\n",
    "train_entropy_df['entropy'] = train_df['image'].apply(compute_entropy)\n",
    "test_entropy_df['entropy'] = test_df['image'].apply(compute_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_n_moment(img, n, pearson = True):\n",
    "    flat_img = img.flatten()\n",
    "    avg = np.mean(flat_img)\n",
    "    std_dev = np.std(flat_img)\n",
    "    total = 0\n",
    "    for i in range(flat_img.shape[0]):\n",
    "        total += ((flat_img[i] - avg)**n)/((flat_img.shape[0] - 1)*std_dev**n)\n",
    "\n",
    "    return total - 3 if (not pearson and n == 4) else total\n",
    "\n",
    "train_skew_df = pd.DataFrame()\n",
    "test_skew_df = pd.DataFrame()\n",
    "train_kurtosis_df = pd.DataFrame()\n",
    "test_kurtosis_df = pd.DataFrame()\n",
    "\n",
    "train_skew_df['skew'] = train_df['image'].apply(lambda x: compute_n_moment(x, 3))\n",
    "test_skew_df['skew'] = test_df['image'].apply(lambda x: compute_n_moment(x, 3))\n",
    "train_kurtosis_df['kurtosis'] = train_df['image'].apply(lambda x: compute_n_moment(x, 4))\n",
    "test_kurtosis_df['kurtosis'] = test_df['image'].apply(lambda x: compute_n_moment(x, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xy_n_moment(img, n, pearson = True):\n",
    "    h,w = np.shape(img)\n",
    "\n",
    "    img_sum = np.sum(img)\n",
    "    x = range(w)\n",
    "    y = range(h)\n",
    "\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "\n",
    "    #Centroid (mean)\n",
    "    cx = np.sum(img*X)/img_sum\n",
    "    cy = np.sum(img*Y)/img_sum\n",
    "\n",
    "    ###Standard deviation\n",
    "    x2 = (range(w) - cx)**2\n",
    "    y2 = (range(h) - cy)**2\n",
    "\n",
    "    X2,Y2 = np.meshgrid(x2,y2)\n",
    "\n",
    "    #Find the variance\n",
    "    vx = np.sum(img*X2)/img_sum\n",
    "    vy = np.sum(img*Y2)/img_sum\n",
    "\n",
    "    #SD is the sqrt of the variance\n",
    "    sx,sy = np.sqrt(vx),np.sqrt(vy)\n",
    "\n",
    "    ### n moment\n",
    "    xn = (range(w) - cx)**n\n",
    "    yn = (range(h) - cy)**n\n",
    "\n",
    "    X3,Y3 = np.meshgrid(xn,yn)\n",
    "\n",
    "    #Find the nth central moment\n",
    "    mnx = np.sum(img*X3)/img_sum\n",
    "    mny = np.sum(img*Y3)/img_sum\n",
    "    #Skewness is the third central moment divided by SD cubed\n",
    "    nx = mnx/sx**n\n",
    "    ny = mny/sy**n\n",
    "\n",
    "    return (nx-3, ny-3) if (not pearson and n == 4) else (nx, ny)\n",
    "\n",
    "train_x_skew_df = pd.DataFrame()\n",
    "test_x_skew_df = pd.DataFrame()\n",
    "train_y_skew_df = pd.DataFrame()\n",
    "test_y_skew_df = pd.DataFrame()\n",
    "\n",
    "train_x_kurtosis_df = pd.DataFrame()\n",
    "test_x_kurtosis_df = pd.DataFrame()\n",
    "train_y_kurtosis_df = pd.DataFrame()\n",
    "test_y_kurtosis_df = pd.DataFrame()\n",
    "\n",
    "train_x_skew_df['x_skew'], train_y_skew_df['y_skew'] = zip(*train_df['image'].apply(lambda x: compute_xy_n_moment(x, 3)))\n",
    "test_x_skew_df['x_skew'], test_y_skew_df['y_skew'] = zip(*test_df['image'].apply(lambda x: compute_xy_n_moment(x, 3)))\n",
    "train_x_kurtosis_df['x_kurtosis'], train_y_kurtosis_df['y_kurtosis'] = zip(*train_df['image'].apply(lambda x: compute_xy_n_moment(x, 4)))\n",
    "test_x_kurtosis_df['x_kurtosis'], test_y_kurtosis_df['y_kurtosis'] = zip(*test_df['image'].apply(lambda x: compute_xy_n_moment(x, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = [1]\n",
    "dirs = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 1, 2, 256)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_df['image'][840]\n",
    "temp_glcm = glcm(img, dists, dirs, 256, True, False, False)\n",
    "m = features.mean(temp_glcm)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.99344676690769"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = train_df['image'][2641]\n",
    "temp_glcm = glcm(img, dists, dirs, 256, True, False, False)\n",
    "nb_dim = temp_glcm.shape[-1]\n",
    "dims = temp_glcm.shape[:-2]\n",
    "\n",
    "u = features.mean(temp_glcm)\n",
    "m1 = 0\n",
    "\n",
    "for index in np.ndindex(dims):\n",
    "    for px in range(nb_dim):\n",
    "        m1 += u[index][0][px]\n",
    "m1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "## glcm mean\n",
    "def compute_glcm_mean(img, dists, dirs, normalise = True, symmetric = False, sum = False):\n",
    "    temp_glcm = glcm(img, dists, dirs, 256, normalise, symmetric, sum)\n",
    "    nb_dim = temp_glcm.shape[-1]\n",
    "    dims = temp_glcm.shape[:-2]\n",
    "\n",
    "    u = features.mean(temp_glcm)\n",
    "    m = 0\n",
    "\n",
    "    for index in np.ndindex(dims):\n",
    "        for px in range(nb_dim):\n",
    "            m += u[index][0][px]\n",
    "    return m\n",
    "\n",
    "train_glcm_mean_df = pd.DataFrame()\n",
    "test_glcm_mean_df = pd.DataFrame()\n",
    "\n",
    "train_glcm_mean_df['glcm_mean'] = train_df['image'].apply(lambda x: compute_glcm_mean(x, dists, dirs))\n",
    "test_glcm_mean_df['glcm_mean'] = test_df['image'].apply(lambda x: compute_glcm_mean(x, dists, dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gsus 40 mins for mean,, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glcm_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.613866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.477282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.881461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.045957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.086247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>21.070858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>20.613695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>19.955627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>19.689847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>19.171299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      glcm_mean\n",
       "0     18.613866\n",
       "1     18.477282\n",
       "2     19.881461\n",
       "3     19.045957\n",
       "4     19.086247\n",
       "...         ...\n",
       "1025  21.070858\n",
       "1026  20.613695\n",
       "1027  19.955627\n",
       "1028  19.689847\n",
       "1029  19.171299\n",
       "\n",
       "[1030 rows x 1 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_glcm_mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## shade and prominence\n",
    "def compute_sp(image, dists, dirs, normalise = True, symmetric = False, sum = False):\n",
    "    sp_list = []\n",
    "    for img in image:\n",
    "        img_sp = []\n",
    "        temp_glcm = glcm(img, dists, dirs, 256, normalise, symmetric, sum)\n",
    "        shade = features.cluster_shade(temp_glcm).reshape(1,-1)[0]\n",
    "        prom = features.cluster_prom(temp_glcm).reshape(1,-1)[0]\n",
    "        for i in shade:\n",
    "            img_sp.append(i)\n",
    "        for j in prom:\n",
    "            img_sp.append(j)\n",
    "        sp_list.append(img_sp)\n",
    "    return sp_list\n",
    "\n",
    "a = [f\"shd_dist{dist}_dir{dir}\" for dist in dists for dir in dirs]\n",
    "a.extend(list(f\"prom_dist{dist}_dir{dir}\" for dist in dists for dir in dirs))\n",
    "\n",
    "train_sp_df = pd.DataFrame(compute_sp(train_df['image'], dists, dir), columns=a)\n",
    "test_sp_df = pd.DataFrame(compute_sp(test_df['image'], dists, dir), columns=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the image data from the DataFrames\n",
    "train_images = train_df['image'].values\n",
    "test_images = test_df['image'].values\n",
    "\n",
    "# Define the function to compute GLCM features for multiple distances and angles\n",
    "def compute_glcm_features(images, distances, angles, properties):\n",
    "    glcm_features = []\n",
    "    for image in images:\n",
    "        image_glcm_features = []\n",
    "        for distance in distances:\n",
    "            for angle in angles:\n",
    "                # Calculate GLCM for each image, distance, and angle\n",
    "                glcm = graycomatrix(image, [distance], [angle], levels=256, symmetric=True, normed=True)\n",
    "                # Compute the specified GLCM properties\n",
    "                texture_features = [graycoprops(glcm, prop)[0, 0] for prop in properties]\n",
    "                image_glcm_features.extend(texture_features)\n",
    "        # Append the computed features for all distances and angles to the result list\n",
    "        glcm_features.append(image_glcm_features)\n",
    "    return glcm_features\n",
    "\n",
    "# Define the GLCM properties you want to compute\n",
    "properties = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "\n",
    "# Define the distances and angles\n",
    "distances = [1, 2, 3]\n",
    "angles = [0, np.pi/4, np.pi/2]\n",
    "\n",
    "# Compute GLCM features for train and test images\n",
    "train_glcm_features = compute_glcm_features(train_images, distances, angles, properties)\n",
    "test_glcm_features = compute_glcm_features(test_images, distances, angles, properties)\n",
    "\n",
    "# Create DataFrames for train and test features\n",
    "X_train = pd.DataFrame(train_glcm_features, columns=[f\"{prop}_d{distance}_a{angle}\" for prop in properties for distance in distances for angle in angles])\n",
    "X_test = pd.DataFrame(test_glcm_features, columns=[f\"{prop}_d{distance}_a{angle}\" for prop in properties for distance in distances for angle in angles])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels from train and test DataFrames\n",
    "y_train = train_df[\"label\"]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['entropy'] = train_entropy_df['entropy']\n",
    "X_test['entropy'] = test_entropy_df['entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['mean'] = train_mean_df['mean']\n",
    "X_test['mean'] = test_mean_df['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['skew'] = train_skew_df['skew']\n",
    "X_test['skew'] = test_skew_df['skew']\n",
    "X_train['kurtosis'] = train_kurtosis_df['kurtosis']\n",
    "X_test['kurtosis'] = test_kurtosis_df['kurtosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['x_skew'] = train_skew_df['x_skew']\n",
    "X_test['x_skew'] = test_skew_df['x_skew']\n",
    "X_train['y_skew'] = train_skew_df['y_skew']\n",
    "X_test['y_skew'] = test_skew_df['y_skew']\n",
    "X_train['x_kurtosis'] = train_kurtosis_df['x_kurtosis']\n",
    "X_test['x_kurtosis'] = test_kurtosis_df['x_kurtosis']\n",
    "X_train['y_kurtosis'] = train_kurtosis_df['y_kurtosis']\n",
    "X_test['y_kurtosis'] = test_kurtosis_df['y_kurtosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['glcm_mean'] = train_glcm_mean_df['glcm_mean']\n",
    "X_test['glcm_mean'] = test_glcm_mean_df['glcm_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, train_sp_df], axis=1)\n",
    "X_test = pd.concat([X_test, test_sp_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4129, 61)\n",
      "(4129,)\n",
      "(1030, 61)\n",
      "(1030,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- cropped //\n",
    "- add mean // 40 mins on my best settings\n",
    "- nth moment (skewness and kurtosis; n = 3, 4)//\n",
    "- glcm mean\n",
    "- glcm variance\n",
    "- entropy // it's shannon\n",
    "- cluster shade // but takes kinda long\n",
    "- cluster prominence // but takes kinda long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"processed_data/glcm/\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "\n",
    "# Save the train and test DataFrames\n",
    "X_train.to_pickle(\"processed_data/glcm/X_train.pkl\")\n",
    "y_train.to_pickle(\"processed_data/glcm/y_train.pkl\")\n",
    "X_test.to_pickle(\"processed_data/glcm/X_test.pkl\")\n",
    "y_test.to_pickle(\"processed_data/glcm/y_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
